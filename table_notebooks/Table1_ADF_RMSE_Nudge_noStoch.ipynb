{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34732751-8b3f-42ff-991c-abcd9e181b18",
   "metadata": {},
   "source": [
    "# YOU NEEED: \n",
    "    - 150 GB to run\n",
    "    - Lots of DASK\n",
    "    \n",
    "## To Run: \n",
    "\n",
    "- Specify desired variable and level in **Specify VAR and Run** cell. \n",
    "- Restart Kernel and Run all Cells \n",
    "- Output is an EXCEL spreadsheet with bootstrapped statistics\n",
    "\n",
    "## Conditionals \n",
    "\n",
    "- if you add a new variable and its small... you probably need to add a conditional to multiply it by 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b04945-6699-4a70-9941-dcf889e0edd0",
   "metadata": {},
   "source": [
    "## Specify VAR and RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fa5a9f3-af3b-4809-9e16-f857b2531eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "vardo = 'VpQp'\n",
    "levdo = 850\n",
    "precip_obs='precip' ## specify 'precip' or 'tp' to switch datasets ... only important if vardo='PRECT'\n",
    "\n",
    "### probably don't touch these.\n",
    "freemod = 'f.e21.DAcompset.f09_d025_free_MJO_1982'\n",
    "years_st = '1982'\n",
    "years_en = '2010'\n",
    "compare_model = 'f.e21.DAcompset.f09_d025_Seasonal_stochai_UV_00_1982'\n",
    "\n",
    "## WOuld you like to skip using dask (ONly if pressure levels don't need to be interepereted)\n",
    "skip_dask=True \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba37f65d-f780-4c6b-919b-cd4f4c956db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import scipy\n",
    "import copy\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "#plotting with Cartopy. \n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "from matplotlib import cm\n",
    "from matplotlib import rc\n",
    "#rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "rc('font',**{'family':'serif','serif':['Times']})\n",
    "rc('text', usetex=True)\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import ticker\n",
    "\n",
    "\n",
    "# import scipy\n",
    "from datetime import datetime\n",
    "import os\n",
    "# import utils\n",
    "import importlib\n",
    "\n",
    "\n",
    "# import statsmodels.api as sm\n",
    "# from windspharm.xarray import VectorWind\n",
    "# from windspharm.standard import VectorWind\n",
    "# from windspharm.examples import example_data_path\n",
    "# from windspharm.tools import prep_data, recover_data, order_latdim\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from shapely.geometry.polygon import LinearRing\n",
    "from dask.diagnostics import ProgressBar\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import matplotlib.patches as mpatches\n",
    "import math\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics import tsaplots\n",
    "import geocat.comp as gcomp\n",
    "import shutil\n",
    "import metpy.calc as mpcalc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec99f7fd-456e-47c1-8871-a12a0ec8f83e",
   "metadata": {},
   "source": [
    "# Experiments: \n",
    "    -Free Running: \n",
    "        -/glade/campaign/cisl/aiml/wchapman/CAM_runs/f.e21.DAcompset.f09_d025_free_MJO_1982\n",
    "    -Nudge No Stochai: \n",
    "        -/glade/scratch/wchapman/archive/f.e21.DAcompset.f09_d025_Seasonal_stochai_UV_00_1982\n",
    "    -Nudge Stochai\n",
    "        -/glade/scratch/wchapman/archive/f.e21.DAcompset.f09_d025_Seasonal_stochai_UV_05_1982_MJO_v3\n",
    "    -DA No Stochai: \n",
    "        -/glade/scratch/wchapman/archive/f.e21.DAcompset.f09_d025_Seasonal_DA_stochai_UV_00_1982\n",
    "    -DA Stochai\n",
    "        -/glade/scratch/wchapman/archive/f.e21.DAcompset.f09_d025_Seasonal_DA_stochai_UV_05_1982/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e0e47b-32cf-4712-b890-6be654b88a9d",
   "metadata": {},
   "source": [
    "## Get ADF to do this for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44433eb4-fbe4-488e-bcbb-99ae3d8a1ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client does not exist yet\n"
     ]
    }
   ],
   "source": [
    "if 'client' in locals():\n",
    "    client.shutdown()\n",
    "    print('...shutdown client...')\n",
    "else:\n",
    "    print('client does not exist yet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45e4dd5e-be44-4f0a-a712-afb9e47e8994",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_dask:\n",
    "    from distributed import Client\n",
    "    from ncar_jobqueue import NCARCluster\n",
    "\n",
    "    cluster = NCARCluster(project='P54048000',walltime='06:00:00')\n",
    "    cluster.scale(40)\n",
    "    client = Client(cluster)\n",
    "    client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352304dd-edfd-4574-8739-9e1ab3c08e41",
   "metadata": {},
   "source": [
    "### helpful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ffd8e8a-48d2-40e3-94c9-4c9ae038c544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "\n",
    "def wgt_rmse(fld1, fld2, wgt):\n",
    "    \"\"\"Calculated the area-weighted RMSE.\n",
    "    Inputs are 2-d spatial fields, fld1 and fld2 with the same shape.\n",
    "    They can be xarray DataArray or numpy arrays.\n",
    "    Input wgt is the weight vector, expected to be 1-d, matching length of one dimension of the data.\n",
    "    Returns a single float value.\n",
    "    \"\"\"\n",
    "    assert len(fld1.shape) == 2,     \"Input fields must have exactly two dimensions.\"\n",
    "    assert fld1.shape == fld2.shape, \"Input fields must have the same array shape.\"\n",
    "    # in case these fields are in dask arrays, compute them now.\n",
    "    if hasattr(fld1, \"compute\"):\n",
    "        fld1 = fld1.compute()\n",
    "    if hasattr(fld2, \"compute\"):\n",
    "        fld2 = fld2.compute()\n",
    "    if isinstance(fld1, xr.DataArray) and isinstance(fld2, xr.DataArray):\n",
    "        return (np.sqrt(((fld1 - fld2)**2).weighted(wgt).mean())).values.item()\n",
    "    else:\n",
    "        check = [len(wgt) == s for s in fld1.shape]\n",
    "        if ~np.any(check):\n",
    "            raise IOError(f\"Sorry, weight array has shape {wgt.shape} which is not compatible with data of shape {fld1.shape}\")\n",
    "        check = [len(wgt) != s for s in fld1.shape]\n",
    "        dimsize = fld1.shape[np.argwhere(check).item()]  # want to get the dimension length for the dim that does not match the size of wgt\n",
    "        warray = np.tile(wgt, (dimsize, 1)).transpose()   # May need more logic to ensure shape is correct.\n",
    "        warray = warray / np.sum(warray) # normalize\n",
    "        wmse = np.nansum(warray * (fld1 - fld2)**2)\n",
    "        return np.sqrt( wmse ).item()\n",
    "\n",
    "#######\n",
    "#annual function\n",
    "def weighted_temporal_mean(ds, var):\n",
    "    \"\"\"\n",
    "    weight by days in each month\n",
    "    \"\"\"\n",
    "    # Determine the month length\n",
    "    month_length = ds.time.dt.days_in_month\n",
    "\n",
    "    # Calculate the weights\n",
    "    wgts = month_length.groupby(\"time.year\") / month_length.groupby(\"time.year\").sum()\n",
    "\n",
    "    # Make sure the weights in each year add up to 1\n",
    "    np.testing.assert_allclose(wgts.groupby(\"time.year\").sum(xr.ALL_DIMS), 1.0)\n",
    "\n",
    "    # Subset our dataset for our variable\n",
    "    obs = ds[var]\n",
    "\n",
    "    # Setup our masking for nan values\n",
    "    cond = obs.isnull()\n",
    "    ones = xr.where(cond, 0.0, 1.0)\n",
    "\n",
    "    # Calculate the numerator\n",
    "    obs_sum = (obs * wgts).resample(time=\"AS\").sum(dim=\"time\")\n",
    "\n",
    "    # Calculate the denominator\n",
    "    ones_out = (ones * wgts).resample(time=\"AS\").sum(dim=\"time\")\n",
    "\n",
    "    # Return the weighted average\n",
    "    return obs_sum / ones_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb935c27-8dc0-495d-877a-4a950ff8ecb3",
   "metadata": {},
   "source": [
    "## Specify VAR and Run..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "562a63eb-855e-47eb-af9e-5b9209270e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free file found!!!\n",
      "/glade/scratch/wchapman/ADF/f.e21.DAcompset.f09_d025_free_MJO_1982/ts/f.e21.DAcompset.f09_d025_free_MJO_1982.h0.VpQp.198201-201012.nc\n",
      "compare file found!!!\n",
      "/glade/scratch/wchapman/ADF/f.e21.DAcompset.f09_d025_Seasonal_stochai_UV_00_1982/ts/f.e21.DAcompset.f09_d025_Seasonal_stochai_UV_00_1982.h0.VpQp.198201-201012.nc\n",
      "LANDFRAC compare file found!!!\n",
      "/\n",
      "...getting obs...\n",
      "CPU times: user 589 ms, sys: 600 ms, total: 1.19 s\n",
      "Wall time: 1.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#find ADF files. \n",
    "#### make if statements for PRECT and TAUx / TAUy\n",
    "\n",
    "if vardo == 'PRECT':\n",
    "    #check for free model files \n",
    "    adf_dir = '/glade/scratch/wchapman/ADF/'+freemod+'/ts/'\n",
    "    fn_free1 = glob.glob(adf_dir+'*.'+'PRECC'+'*'+years_st+'*'+years_en+'*')\n",
    "    fn_free2 = glob.glob(adf_dir+'*.'+'PRECL'+'*'+years_st+'*'+years_en+'*')\n",
    "    \n",
    "    if (len(fn_free1) == 0) |  (len(fn_free2) == 0): \n",
    "        fn_no = glob.glob(adf_dir+'/*.nc')\n",
    "        for fnss in fn_no:\n",
    "            print(fnss)\n",
    "        raise Exception(\"variables PRECC and PRECL is not in the free model directory...run ADF\")  \n",
    "    else:\n",
    "        print('free file found!!!')\n",
    "        print(fn_free1[0])\n",
    "        print(fn_free2[0])\n",
    "\n",
    "    #check for compare model files \n",
    "    adf_dir = '/glade/scratch/wchapman/ADF/'+compare_model+'/ts/'\n",
    "    fn_comp1 = glob.glob(adf_dir+'*.'+'PRECC'+'*'+years_st+'*'+years_en+'*.nc')\n",
    "    fn_comp2 = glob.glob(adf_dir+'*.'+'PRECL'+'*'+years_st+'*'+years_en+'*.nc') \n",
    "    if (len(fn_comp1) == 0) |  (len(fn_comp2) == 0): \n",
    "        fn_no = glob.glob(adf_dir+'/*.nc')\n",
    "        for fnss in fn_no:\n",
    "            print(fnss)\n",
    "        raise Exception(\"variables PRECC and PRECL not in the compare model directory...run ADF\")  \n",
    "    else:\n",
    "        print('compare file found!!!')\n",
    "        print(fn_comp1[0])\n",
    "        print(fn_comp2[0])\n",
    "    \n",
    "    #open variables: \n",
    "    DS_comp = xr.open_mfdataset([fn_comp1[0],fn_comp2[0]]).load()\n",
    "    DS_comp['PRECT']=(DS_comp['PRECC']+DS_comp['PRECL'])*86400*1000\n",
    "    DS_comp=DS_comp.drop_vars(['PRECC','PRECL'])\n",
    "    \n",
    "    DS_free = xr.open_mfdataset([fn_free1[0],fn_free2[0]]).load()\n",
    "    DS_free['PRECT']=(DS_free['PRECC']+DS_free['PRECL'])*86400*1000\n",
    "    DS_free=DS_free.drop_vars(['PRECC','PRECL'])\n",
    "\n",
    "elif vardo == 'TAUX':\n",
    "    \n",
    "    #check for free model files \n",
    "    adf_dir = '/glade/scratch/wchapman/ADF/'+freemod+'/ts/'\n",
    "    fn_free1 = glob.glob(adf_dir+'*.'+'TAUX'+'*'+years_st+'*'+years_en+'*')\n",
    "    fn_free2 = glob.glob(adf_dir+'*.'+'TAUGWX'+'*'+years_st+'*'+years_en+'*')\n",
    "    \n",
    "    if (len(fn_free1) == 0) |  (len(fn_free2) == 0): \n",
    "        fn_no = glob.glob(adf_dir+'/*.nc')\n",
    "        for fnss in fn_no:\n",
    "            print(fnss)\n",
    "        raise Exception(\"variables TAUX and TAUGWX is not in the free model directory...run ADF\")  \n",
    "    else:\n",
    "        print('free file found!!!')\n",
    "        print(fn_free1[0])\n",
    "        print(fn_free2[0])\n",
    "\n",
    "    #check for compare model files \n",
    "    adf_dir = '/glade/scratch/wchapman/ADF/'+compare_model+'/ts/'\n",
    "    fn_comp1 = glob.glob(adf_dir+'*.'+'TAUX'+'*'+years_st+'*'+years_en+'*.nc')\n",
    "    fn_comp2 = glob.glob(adf_dir+'*.'+'TAUGWX'+'*'+years_st+'*'+years_en+'*.nc') \n",
    "    if (len(fn_comp1) == 0) |  (len(fn_comp2) == 0): \n",
    "        fn_no = glob.glob(adf_dir+'/*.nc')\n",
    "        for fnss in fn_no:\n",
    "            print(fnss)\n",
    "        raise Exception(\"variables TAUX and TAUGWX not in the compare model directory...run ADF\")  \n",
    "    else:\n",
    "        print('compare file found!!!')\n",
    "        print(fn_comp1[0])\n",
    "        print(fn_comp2[0])\n",
    "        \n",
    "     \n",
    "    DS_comp = xr.open_mfdataset([fn_comp1[0],fn_comp2[0]]).load()\n",
    "    DS_comp['tau_nox'] = -(DS_comp['TAUX']-DS_comp['TAUGWX'])*100000\n",
    "    DS_comp=DS_comp.drop_vars(['TAUX','TAUGWX'])\n",
    "    DS_comp=DS_comp.rename({'tau_nox':vardo})\n",
    "    \n",
    "    DS_free = xr.open_mfdataset([fn_free1[0],fn_free2[0]]).load()\n",
    "    DS_free['tau_nox'] = -(DS_free['TAUX']-DS_free['TAUGWX'])*100000\n",
    "    DS_free=DS_free.drop_vars(['TAUX','TAUGWX'])\n",
    "    DS_free=DS_free.rename({'tau_nox':vardo})\n",
    "    \n",
    "elif vardo == 'TAUY':\n",
    "    raise Exception(\"TAUY has not been handled yet\")  \n",
    "\n",
    "elif vardo == 'Q':\n",
    "    #check for free model files \n",
    "    adf_dir = '/glade/scratch/wchapman/ADF/'+freemod+'/ts/'\n",
    "    fn_free = glob.glob(adf_dir+'*.'+vardo+'.*'+years_st+'*'+years_en+'*')\n",
    "    if len(fn_free) == 0: \n",
    "        fn_no = glob.glob(adf_dir+'/*.nc')\n",
    "        for fnss in fn_no:\n",
    "            print(fnss)\n",
    "        raise Exception(\"variabile is not in the free model directory...run ADF\")  \n",
    "    else:\n",
    "        print('free file found!!!')\n",
    "        print(fn_free[0])\n",
    "\n",
    "    #check for compare model files \n",
    "    adf_dir = '/glade/scratch/wchapman/ADF/'+compare_model+'/ts/'\n",
    "    fn_comp = glob.glob(adf_dir+'*.'+vardo+'.*'+years_st+'*'+years_en+'*.nc')\n",
    "    if len(fn_comp) == 0: \n",
    "        fn_no = glob.glob(adf_dir+'/*.nc')\n",
    "        for fnss in fn_no:\n",
    "            print(fnss)\n",
    "        raise Exception(\"variabile is not in the compare model directory...run ADF\")  \n",
    "    else:\n",
    "        print('compare file found!!!')\n",
    "        print(fn_comp[0])\n",
    "    \n",
    "    #open variables: \n",
    "    DS_comp = xr.open_dataset(fn_comp[0])\n",
    "    DS_free = xr.open_dataset(fn_free[0])\n",
    "    DS_comp[vardo] = xr.open_dataset(fn_comp[0])[vardo]*10000    \n",
    "    DS_free[vardo] = xr.open_dataset(fn_free[0])[vardo]*10000\n",
    "    \n",
    "else:\n",
    "    #check for free model files \n",
    "    adf_dir = '/glade/scratch/wchapman/ADF/'+freemod+'/ts/'\n",
    "    fn_free = glob.glob(adf_dir+'*.'+vardo+'.*'+years_st+'*'+years_en+'*')\n",
    "    if len(fn_free) == 0: \n",
    "        fn_no = glob.glob(adf_dir+'/*.nc')\n",
    "        for fnss in fn_no:\n",
    "            print(fnss)\n",
    "        raise Exception(\"variabile is not in the free model directory...run ADF\")  \n",
    "    else:\n",
    "        print('free file found!!!')\n",
    "        print(fn_free[0])\n",
    "\n",
    "    #check for compare model files \n",
    "    adf_dir = '/glade/scratch/wchapman/ADF/'+compare_model+'/ts/'\n",
    "    fn_comp = glob.glob(adf_dir+'*.'+vardo+'.*'+years_st+'*'+years_en+'*.nc')\n",
    "    if len(fn_comp) == 0: \n",
    "        fn_no = glob.glob(adf_dir+'/*.nc')\n",
    "        for fnss in fn_no:\n",
    "            print(fnss)\n",
    "        raise Exception(\"variabile is not in the compare model directory...run ADF\")  \n",
    "    else:\n",
    "        print('compare file found!!!')\n",
    "        print(fn_comp[0])\n",
    "    \n",
    "    #open variables: \n",
    "    DS_comp = xr.open_dataset(fn_comp[0])\n",
    "    DS_free = xr.open_dataset(fn_free[0])\n",
    "    \n",
    "    if vardo == 'VpQp':\n",
    "        DS_comp = DS_comp*10000\n",
    "        DS_free = DS_free*10000\n",
    "        \n",
    "\n",
    "#re-align time...\n",
    "DS_comp['time'] = pd.date_range(start=years_st+'-01-01',end=years_en+'-12-01',freq='MS')\n",
    "DS_free['time'] = pd.date_range(start=years_st+'-01-01',end=years_en+'-12-01',freq='MS')\n",
    "\n",
    "lndfile_ = '/glade/scratch/wchapman/ADF/'+compare_model+'/ts/*LANDFRAC*'+'.*'+years_st+'*'+years_en+'*.nc'\n",
    "fn_lndfile=glob.glob(lndfile_)[0]\n",
    "\n",
    "if len(fn_lndfile) == 0: \n",
    "    fn_no = glob.glob(adf_dir+'/*.nc')\n",
    "    for fnss in fn_no:\n",
    "        print(fnss)\n",
    "    raise Exception(\"LANDFRAC is not in the compare model directory...run ADF\")  \n",
    "else:\n",
    "    print('LANDFRAC compare file found!!!')\n",
    "    print(fn_lndfile[0])\n",
    "    DS_LandFrac = xr.open_dataset(fn_lndfile)\n",
    "    DS_LandFrac_season = DS_LandFrac.groupby(\"time.season\").sum(dim=\"time\")\n",
    "    Annual_landfrac = weighted_temporal_mean(DS_LandFrac,'LANDFRAC').mean('time')\n",
    "    Annual_landfrac = Annual_landfrac.assign_coords(season='ANN')\n",
    "    Annual_landfrac = Annual_landfrac.expand_dims('season')\n",
    "    Annual_landfrac = Annual_landfrac.to_dataset(name='LANDFRAC')\n",
    "    DS_LandFrac_season = xr.merge([Annual_landfrac,DS_LandFrac_season])\n",
    "\n",
    "\n",
    "#grab_landfrac \n",
    "#FUNCTION:\n",
    "#interpolate data\n",
    "keys_list = list(DS_free.keys())\n",
    "if 'hyam' in keys_list:\n",
    "    surf_var = False\n",
    "    DS_comp = DS_comp.chunk({'time':10, 'lat':192, 'lon':288})\n",
    "    DS_free = DS_free.chunk({'time':10, 'lat':192, 'lon':288})\n",
    "    print('First Regrid then seek user input')\n",
    "    new_levs = np.array([3, 7, 20, 30, 50, 70, 100, 125, 150, 200, 250, 300, 350, 400, 450, 500, 600, 700, 800, 850, 900, 925, 950, 975, 1000])*100 #mb\n",
    "    DS_comp_int = gcomp.interpolation.interp_hybrid_to_pressure(DS_comp[vardo],DS_comp['PS'],DS_comp['hyam'],DS_comp['hybm'],100000.,new_levels=new_levs).persist()\n",
    "    DS_comp_int =  DS_comp_int.rename({\"plev\": \"lev\"})\n",
    "    DS_comp_int[\"lev\"] =  DS_comp_int[\"lev\"] / 100.0\n",
    "    print('computing')\n",
    "    DS_comp_int =  DS_comp_int.compute()\n",
    "    print('interpolation of ',vardo,'..finished comp..')\n",
    "    \n",
    "    \n",
    "    DS_free_int = gcomp.interpolation.interp_hybrid_to_pressure(DS_free[vardo],DS_free['PS'],DS_free['hyam'],DS_free['hybm'],100000.,new_levels=new_levs).persist()\n",
    "    DS_free_int =  DS_free_int.rename({\"plev\": \"lev\"})\n",
    "    DS_free_int[\"lev\"] =  DS_free_int[\"lev\"] / 100.0\n",
    "    print('computing')\n",
    "    DS_free_int =  DS_free_int.compute()\n",
    "    print('interpolation of ',vardo,'..finished total..')\n",
    "    print('enter level:')\n",
    "    DS_free_int = DS_free_int.sel(lev=levdo)\n",
    "    DS_comp_int = DS_comp_int.sel(lev=levdo)\n",
    "elif np.isin(vardo,['VpVp','VpQp','EKE']):\n",
    "    surf_var = False\n",
    "    DS_free_int = DS_free.sel(lev=levdo).compute()\n",
    "    DS_comp_int = DS_comp.sel(lev=levdo).compute()\n",
    "    DS_free_int = DS_free_int[vardo]\n",
    "    DS_comp_int = DS_comp_int[vardo]\n",
    "else:\n",
    "    surf_var = True\n",
    "    levdo = 'surf'\n",
    "    DS_free_int = DS_free.compute()\n",
    "    DS_comp_int = DS_comp.compute()\n",
    "    DS_free_int = DS_free_int[vardo]\n",
    "    DS_comp_int = DS_comp_int[vardo]\n",
    "    \n",
    "#FUNCTION:\n",
    "#get obs \n",
    "print('...getting obs...')\n",
    "ERAds1 = xr.open_dataset('/glade/work/wchapman/ERAi_Obs/ERAinterim.OTHERVARS.camgrid.1979-2010.nc').sel(time=slice(years_st+'-01-01',years_en+'-12-01'))\n",
    "ERAds2 = xr.open_dataset('/glade/work/wchapman/ERAi_Obs/ERAinterim.UV.camgrid.1979-2010.nc').sel(time=slice(years_st+'-01-01',years_en+'-12-01'))\n",
    "ERAds3 = xr.open_dataset('/glade/work/wchapman/ERAi_Obs/ERAinterim.fc12hr.sfc.camgrid.1979-2010.nc').sel(time=slice(years_st+'-01-01',years_en+'-12-01'))\n",
    "ERAds4 = xr.open_dataset('/glade/work/wchapman/ERAi_Obs/ERAinterim.an.sfc.camgrid.1979-2010.nc').sel(time=slice(years_st+'-01-01',years_en+'-12-01'))\n",
    "ERAds5 = xr.open_dataset('/glade/work/wchapman/ERAi_Obs/GPCP.prec.camgrid.1979-2010.nc').sel(time=slice(years_st+'-01-01',years_en+'-12-01'))\n",
    "ERAds6 = xr.open_dataset('/glade/work/wchapman/ERAi_Obs/ERAinterim.HF.camgrid.1979-2010.nc').sel(time=slice(years_st+'-01-01',years_en+'-12-01'))\n",
    "\n",
    "ERAi = xr.merge([ERAds1,ERAds2,ERAds3,ERAds4.drop_vars(\"z\"),ERAds5])\n",
    "ERAi = ERAi.sel(time=slice(years_st+'-01-01',years_en+'-12-01'))\n",
    "\n",
    "mapping_var_dict = {'U':'u','V':'v','T':'t','Q':'q','Z3':'z','OMEGA':'w','TREFHT':'t2m','PSL':'msl','PRECT':precip_obs,'TAUX':'ewss', 'VpVp':'VpVp','VpQp':'VpQp','EKE':'EKE'}\n",
    "vardo_era = mapping_var_dict[vardo]\n",
    "\n",
    "if vardo_era == 'tp':\n",
    "    ERAi = ERAi[vardo_era]*10000\n",
    "elif vardo_era == 'precip':\n",
    "    ERAi = ERAi[vardo_era]\n",
    "elif vardo_era == 'ewss':\n",
    "    ERAi = ERAi[vardo_era]\n",
    "elif vardo_era =='q':\n",
    "    ERAi = ERAi[vardo_era]*10000\n",
    "elif np.isin(vardo_era,['VpVp','VpQp','EKE']):\n",
    "    ERAi = ERAds6[vardo_era].sel(lev=levdo)\n",
    "    if vardo_era =='VpQp':\n",
    "        ERAi = ERAi*10000\n",
    "else: \n",
    "    ERAi = ERAi[vardo_era]\n",
    "\n",
    "if 'hyam' in keys_list:\n",
    "    ERAi = (ERAi.sel(level=[3, 7, 20, 30, 50, 70, 100, 125, 150, 200, 250, 300, 350, 400, 450, 500, 600, 700, 800, 850, 900, 925, 950, 975, 1000]))\n",
    "    ERAi =  ERAi.rename({\"level\": \"lev\"})\n",
    "    ERAi = ERAi.sel(lev=levdo)\n",
    "    \n",
    "ERAi = ERAi.compute()\n",
    "\n",
    "##add an exception for VpQp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79fd8af-a847-4cd9-be91-4f780e2bf8c1",
   "metadata": {},
   "source": [
    "## Remove the Dask Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "412b4934-8f87-4438-be9f-4d338dea3498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client does not exist yet\n"
     ]
    }
   ],
   "source": [
    "if 'client' in locals():\n",
    "    client.shutdown()\n",
    "    print('...shutdown client...')\n",
    "else:\n",
    "    print('client does not exist yet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4708b70-83d5-409d-9656-dfe1fa00ddfa",
   "metadata": {},
   "source": [
    "## Bootstrap Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8550bb0f-d263-4c8c-9bba-a7f168e32421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "...doing actual...\n",
      "###################\n",
      "...doing annual...\n",
      "###################\n",
      "0\n",
      "...done bootstrapping...\n",
      "CPU times: user 6.32 s, sys: 2.02 s, total: 8.34 s\n",
      "Wall time: 8.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##read this... confusing result with doing replacement:\n",
    "#https://web.ma.utexas.edu/users/parker/sampling/woreplshort.htm#without\n",
    "#https://stats.stackexchange.com/questions/69744/why-at-all-consider-sampling-without-replacement-in-a-practical-application\n",
    "#Bootstrap: \n",
    "bs_nummy = 10\n",
    "LF_scale = 0.1 \n",
    "if vardo=='TREFHT':\n",
    "    LF_scale=1\n",
    "    print('Land Scale:', 1)\n",
    "seas = ['DJF','MAM','JJA','SON']\n",
    "#latitude weighting.\n",
    "weights_cos = np.cos(np.deg2rad(DS_free_int.lat))\n",
    "weights_cos.name = \"weights\"\n",
    "\n",
    "## set up years: \n",
    "\n",
    "yers_len = len(np.unique(DS_comp_int['time.year']))\n",
    "\n",
    "DJF_ints = np.arange(0,3)\n",
    "DJF_all=[]\n",
    "for ii in range(yers_len):\n",
    "    DJF_all.append(list(DJF_ints+12*ii))\n",
    "DJF_all = np.array(DJF_all).flatten()\n",
    "\n",
    "MAM_ints = np.arange(3,6)\n",
    "MAM_all=[]\n",
    "for ii in range(yers_len):\n",
    "    MAM_all.append(list(MAM_ints+12*ii))\n",
    "MAM_all = np.array(MAM_all).flatten()\n",
    "\n",
    "JJA_ints = np.arange(6,9)\n",
    "JJA_all=[]\n",
    "for ii in range(yers_len):\n",
    "    JJA_all.append(list(JJA_ints+12*ii))\n",
    "JJA_all = np.array(JJA_all).flatten()\n",
    "\n",
    "SON_ints = np.arange(9,12)\n",
    "SON_all=[]\n",
    "for ii in range(yers_len):\n",
    "    SON_all.append(list(SON_ints+12*ii))\n",
    "SON_all = np.array(SON_all).flatten()\n",
    "\n",
    "#dictionaries for RMSE\n",
    "RMSE_dict_free={'DJF_global':[],'MAM_global':[],'JJA_global':[],'SON_global':[],'ANN_global':[],\n",
    "               'DJF_trop':[],'MAM_trop':[],'JJA_trop':[],'SON_trop':[],'ANN_trop':[],\n",
    "               'DJF_extrop':[],'MAM_extrop':[],'JJA_extrop':[],'SON_extrop':[],'ANN_extrop':[],\n",
    "               'DJF_land':[],'MAM_land':[],'JJA_land':[],'SON_land':[],'ANN_land':[],\n",
    "               'DJF_ocean':[],'MAM_ocean':[],'JJA_ocean':[],'SON_ocean':[],'ANN_ocean':[]}\n",
    "\n",
    "RMSE_dict_comp={'DJF_global':[],'MAM_global':[],'JJA_global':[],'SON_global':[],'ANN_global':[],\n",
    "               'DJF_trop':[],'MAM_trop':[],'JJA_trop':[],'SON_trop':[],'ANN_trop':[],\n",
    "               'DJF_extrop':[],'MAM_extrop':[],'JJA_extrop':[],'SON_extrop':[],'ANN_extrop':[],\n",
    "               'DJF_land':[],'MAM_land':[],'JJA_land':[],'SON_land':[],'ANN_land':[],\n",
    "               'DJF_ocean':[],'MAM_ocean':[],'JJA_ocean':[],'SON_ocean':[],'ANN_ocean':[]}\n",
    "\n",
    "\n",
    "lat = DS_free_int['lat']\n",
    "res_all = []\n",
    "for bs_ii in range(bs_nummy):\n",
    "    if bs_ii % 20 ==0:\n",
    "        print(bs_ii)\n",
    "    \n",
    "    #sample from each season equally: \n",
    "    \n",
    "    D_int=random.sample(list(DJF_all),k=int(len(DJF_all)*0.8))\n",
    "    M_int=random.sample(list(MAM_all),k=int(len(DJF_all)*0.8))\n",
    "    J_int=random.sample(list(JJA_all),k=int(len(DJF_all)*0.8))\n",
    "    S_int=random.sample(list(SON_all),k=int(len(DJF_all)*0.8))\n",
    "    res = list(np.array([D_int,M_int,J_int,S_int]).flatten())\n",
    "    res_all.append(res)\n",
    "    #select equally random in time per season.....\n",
    "    \n",
    "    \n",
    "    DS_free_temp = DS_free_int.isel(time=res)\n",
    "    DS_comp_temp = DS_comp_int.isel(time=res)\n",
    "    ERAi_temp = ERAi.isel(time=res)\n",
    "    \n",
    "    month_length = DS_free_temp.time.dt.days_in_month\n",
    "    weights = (month_length.groupby(\"time.season\") / month_length.groupby(\"time.season\").sum())\n",
    "    np.testing.assert_allclose(weights.groupby(\"time.season\").sum().values, np.ones(4))\n",
    "    DS_free_weighted = (DS_free_temp * weights).groupby(\"time.season\").sum(dim=\"time\",skipna=False)\n",
    "    DS_comp_weighted = (DS_comp_temp * weights).groupby(\"time.season\").sum(dim=\"time\",skipna=False)\n",
    "    ERAi_weighted = (ERAi_temp * weights).groupby(\"time.season\").sum(dim=\"time\",skipna=False)\n",
    "    ERAi_weighted.to_dataset(name=vardo)\n",
    "    DS_free_weighted.to_dataset(name=vardo)\n",
    "    DS_comp_weighted.to_dataset(name=vardo)\n",
    "    \n",
    "    \n",
    "    #get RMSE by season. \n",
    "    for seas_do in seas:\n",
    "        if vardo=='TREFHT': #correct for prescribed ocean... \n",
    "            plotter_obs = ERAi_weighted.sel(season=seas_do)\n",
    "            plotter_obs = plotter_obs.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "        \n",
    "            plotter_free = DS_free_weighted.sel(season=seas_do)\n",
    "            plotter_free = plotter_free.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "        \n",
    "            plotter_comp = DS_comp_weighted.sel(season=seas_do)\n",
    "            plotter_comp = plotter_comp.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "            \n",
    "            #global\n",
    "            RMSE_dict_free[seas_do+'_global'].append(np.round(wgt_rmse(plotter_obs.sel(lat=slice(-87,87)),plotter_free.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "            RMSE_dict_comp[seas_do+'_global'].append(np.round(wgt_rmse(plotter_obs.sel(lat=slice(-87,87)),plotter_comp.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "\n",
    "            #extropics \n",
    "            plotter_free_extrop = plotter_free.where((lat>25)|(lat<-25),np.nan)\n",
    "            plotter_free_extrop = plotter_free_extrop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "        \n",
    "            plotter_comp_extrop = plotter_comp.where((lat>25)|(lat<-25),np.nan)\n",
    "            plotter_comp_extrop = plotter_comp_extrop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "\n",
    "            plotter_obs_extrop = plotter_obs.where((lat>25)|(lat<-25),np.nan)\n",
    "            plotter_obs_extrop = plotter_obs_extrop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "\n",
    "            RMSE_dict_free[seas_do+'_extrop'].append(np.round(wgt_rmse(plotter_obs_extrop.sel(lat=slice(-87,87)),plotter_free_extrop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "            RMSE_dict_comp[seas_do+'_extrop'].append(np.round(wgt_rmse(plotter_obs_extrop.sel(lat=slice(-87,87)),plotter_comp_extrop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "\n",
    "            #tropics \n",
    "            plotter_free_trop = plotter_free.where((lat<25)&(lat>-25),np.nan)\n",
    "            plotter_comp_trop = plotter_comp.where((lat<25)&(lat>-25),np.nan)\n",
    "            plotter_obs_trop = plotter_obs.where((lat<25)&(lat>-25),np.nan)\n",
    "\n",
    "            RMSE_dict_free[seas_do+'_trop'].append(np.round(wgt_rmse(plotter_obs_trop.sel(lat=slice(-87,87)),plotter_free_trop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "            RMSE_dict_comp[seas_do+'_trop'].append(np.round(wgt_rmse(plotter_obs_trop.sel(lat=slice(-87,87)),plotter_comp_trop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "        elif vardo=='TAUX':\n",
    "            plotter_obs = ERAi_weighted.sel(season=seas_do)\n",
    "            plotter_obs = plotter_obs.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "        \n",
    "            plotter_free = DS_free_weighted.sel(season=seas_do)\n",
    "            plotter_free = plotter_free.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "        \n",
    "            plotter_comp = DS_comp_weighted.sel(season=seas_do)\n",
    "            plotter_comp = plotter_comp.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "            \n",
    "            #global\n",
    "            RMSE_dict_free[seas_do+'_global'].append(np.round(wgt_rmse(plotter_obs.sel(lat=slice(-87,87)),plotter_free.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "            RMSE_dict_comp[seas_do+'_global'].append(np.round(wgt_rmse(plotter_obs.sel(lat=slice(-87,87)),plotter_comp.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "\n",
    "            #extropics \n",
    "            plotter_free_extrop = plotter_free.where((lat>25)|(lat<-25),np.nan)\n",
    "            plotter_free_extrop = plotter_free_extrop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "        \n",
    "            plotter_comp_extrop = plotter_comp.where((lat>25)|(lat<-25),np.nan)\n",
    "            plotter_comp_extrop = plotter_comp_extrop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "\n",
    "            plotter_obs_extrop = plotter_obs.where((lat>25)|(lat<-25),np.nan)\n",
    "            plotter_obs_extrop = plotter_obs_extrop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "\n",
    "            RMSE_dict_free[seas_do+'_extrop'].append(np.round(wgt_rmse(plotter_obs_extrop.sel(lat=slice(-87,87)),plotter_free_extrop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "            RMSE_dict_comp[seas_do+'_extrop'].append(np.round(wgt_rmse(plotter_obs_extrop.sel(lat=slice(-87,87)),plotter_comp_extrop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "\n",
    "            #tropics \n",
    "            plotter_free_trop = plotter_free.where((lat<25)&(lat>-25),np.nan)\n",
    "            plotter_free_trop = plotter_free_trop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "            plotter_comp_trop = plotter_comp.where((lat<25)&(lat>-25),np.nan)\n",
    "            plotter_comp_trop = plotter_comp_trop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "            plotter_obs_trop = plotter_obs.where((lat<25)&(lat>-25),np.nan)\n",
    "            plotter_obs_trop = plotter_obs_trop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "\n",
    "\n",
    "            RMSE_dict_free[seas_do+'_trop'].append(np.round(wgt_rmse(plotter_obs_trop.sel(lat=slice(-87,87)),plotter_free_trop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "            RMSE_dict_comp[seas_do+'_trop'].append(np.round(wgt_rmse(plotter_obs_trop.sel(lat=slice(-87,87)),plotter_comp_trop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "            \n",
    "        else:\n",
    "            plotter_obs = ERAi_weighted.sel(season=seas_do)\n",
    "            plotter_free = DS_free_weighted.sel(season=seas_do)\n",
    "            plotter_comp = DS_comp_weighted.sel(season=seas_do)\n",
    "\n",
    "            #global\n",
    "            RMSE_dict_free[seas_do+'_global'].append(np.round(wgt_rmse(plotter_obs.sel(lat=slice(-87,87)),plotter_free.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "            RMSE_dict_comp[seas_do+'_global'].append(np.round(wgt_rmse(plotter_obs.sel(lat=slice(-87,87)),plotter_comp.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "\n",
    "            #extropics \n",
    "            plotter_free_extrop = plotter_free.where((lat>25)|(lat<-25),np.nan)\n",
    "            plotter_comp_extrop = plotter_comp.where((lat>25)|(lat<-25),np.nan)\n",
    "            plotter_obs_extrop = plotter_obs.where((lat>25)|(lat<-25),np.nan)\n",
    "\n",
    "            RMSE_dict_free[seas_do+'_extrop'].append(np.round(wgt_rmse(plotter_obs_extrop.sel(lat=slice(-87,87)),plotter_free_extrop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "            RMSE_dict_comp[seas_do+'_extrop'].append(np.round(wgt_rmse(plotter_obs_extrop.sel(lat=slice(-87,87)),plotter_comp_extrop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "\n",
    "            #tropics \n",
    "            plotter_free_trop = plotter_free.where((lat<25)&(lat>-25),np.nan)\n",
    "            plotter_comp_trop = plotter_comp.where((lat<25)&(lat>-25),np.nan)\n",
    "            plotter_obs_trop = plotter_obs.where((lat<25)&(lat>-25),np.nan)\n",
    "\n",
    "            RMSE_dict_free[seas_do+'_trop'].append(np.round(wgt_rmse(plotter_obs_trop.sel(lat=slice(-87,87)),plotter_free_trop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "            RMSE_dict_comp[seas_do+'_trop'].append(np.round(wgt_rmse(plotter_obs_trop.sel(lat=slice(-87,87)),plotter_comp_trop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "\n",
    "        if surf_var:\n",
    "            if vardo==\"TREFHT\":\n",
    "                seas_do_lf = 'ANN'\n",
    "            else:\n",
    "                seas_do_lf = seas_do\n",
    "            \n",
    "            plotter_obs = ERAi_weighted.sel(season=seas_do)\n",
    "            plotter_free = DS_free_weighted.sel(season=seas_do)\n",
    "            plotter_comp = DS_comp_weighted.sel(season=seas_do)\n",
    "            \n",
    "            plotter_obs_ocean = plotter_obs.where(DS_LandFrac_season.sel(season=seas_do_lf).LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "            plotter_obs_land = plotter_obs.where(DS_LandFrac_season.sel(season=seas_do_lf).LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "            plotter_free_ocean = plotter_free.where(DS_LandFrac_season.sel(season=seas_do_lf).LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "            plotter_free_land = plotter_free.where(DS_LandFrac_season.sel(season=seas_do_lf).LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "            plotter_comp_ocean = plotter_comp.where(DS_LandFrac_season.sel(season=seas_do_lf).LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "            plotter_comp_land = plotter_comp.where(DS_LandFrac_season.sel(season=seas_do_lf).LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "\n",
    "            #land            \n",
    "            RMSE_dict_free[seas_do+'_land'].append(np.round(wgt_rmse(plotter_obs_land.sel(lat=slice(-87,87)),plotter_free_land.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "            RMSE_dict_comp[seas_do+'_land'].append(np.round(wgt_rmse(plotter_obs_land.sel(lat=slice(-87,87)),plotter_comp_land.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "        \n",
    "            #ocean \n",
    "            RMSE_dict_free[seas_do+'_ocean'].append(np.round(wgt_rmse(plotter_obs_ocean.sel(lat=slice(-87,87)),plotter_free_ocean.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "            RMSE_dict_comp[seas_do+'_ocean'].append(np.round(wgt_rmse(plotter_obs_ocean.sel(lat=slice(-87,87)),plotter_comp_ocean.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "        \n",
    "        \n",
    "print('...doing actual...')\n",
    "month_length = DS_free_int.time.dt.days_in_month\n",
    "weights = (month_length.groupby(\"time.season\") / month_length.groupby(\"time.season\").sum())\n",
    "np.testing.assert_allclose(weights.groupby(\"time.season\").sum().values, np.ones(4))\n",
    "\n",
    "DS_free_weighted = (DS_free_int * weights).groupby(\"time.season\").sum(dim=\"time\",skipna=False)\n",
    "DS_comp_weighted = (DS_comp_int * weights).groupby(\"time.season\").sum(dim=\"time\",skipna=False)\n",
    "ERAi_weighted = (ERAi * weights).groupby(\"time.season\").sum(dim=\"time\",skipna=False)\n",
    "\n",
    "ERAi_weighted.to_dataset(name=vardo)\n",
    "DS_free_weighted.to_dataset(name=vardo)\n",
    "DS_comp_weighted.to_dataset(name=vardo)\n",
    "\n",
    "for seas_do in seas:\n",
    "    if vardo =='TREFHT': #correct for prescribed ocean... \n",
    "                \n",
    "        plotter_obs = ERAi_weighted.sel(season=seas_do)\n",
    "        plotter_obs = plotter_obs.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "        \n",
    "        plotter_free = DS_free_weighted.sel(season=seas_do)\n",
    "        plotter_free = plotter_free.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "        \n",
    "        plotter_comp = DS_comp_weighted.sel(season=seas_do)\n",
    "        plotter_comp = plotter_comp.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "\n",
    "        #global\n",
    "        RMSE_dict_free[seas_do+'_global'].append(np.round(wgt_rmse(plotter_obs.sel(lat=slice(-87,87)),plotter_free.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "        RMSE_dict_comp[seas_do+'_global'].append(np.round(wgt_rmse(plotter_obs.sel(lat=slice(-87,87)),plotter_comp.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "\n",
    "        #extropics \n",
    "        plotter_free_extrop = plotter_free.where((lat>25)|(lat<-25),np.nan)\n",
    "        plotter_free_extrop = plotter_free_extrop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "        \n",
    "        plotter_comp_extrop = plotter_comp.where((lat>25)|(lat<-25),np.nan)\n",
    "        plotter_comp_extrop = plotter_comp_extrop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "\n",
    "        plotter_obs_extrop = plotter_obs.where((lat>25)|(lat<-25),np.nan)\n",
    "        plotter_obs_extrop = plotter_obs_extrop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "\n",
    "        RMSE_dict_free[seas_do+'_extrop'].append(np.round(wgt_rmse(plotter_obs_extrop.sel(lat=slice(-87,87)),plotter_free_extrop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "        RMSE_dict_comp[seas_do+'_extrop'].append(np.round(wgt_rmse(plotter_obs_extrop.sel(lat=slice(-87,87)),plotter_comp_extrop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "\n",
    "        #tropics \n",
    "        plotter_free_trop = plotter_free.where((lat<25)&(lat>-25),np.nan)\n",
    "        plotter_free_trop = plotter_free_trop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "\n",
    "        plotter_comp_trop = plotter_comp.where((lat<25)&(lat>-25),np.nan)\n",
    "        plotter_comp_trop = plotter_comp_trop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "        \n",
    "        plotter_obs_trop = plotter_obs.where((lat<25)&(lat>-25),np.nan)\n",
    "        plotter_obs_trop = plotter_obs_trop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "\n",
    "        RMSE_dict_free[seas_do+'_trop'].append(np.round(wgt_rmse(plotter_obs_trop.sel(lat=slice(-87,87)),plotter_free_trop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "        RMSE_dict_comp[seas_do+'_trop'].append(np.round(wgt_rmse(plotter_obs_trop.sel(lat=slice(-87,87)),plotter_comp_trop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3)) \n",
    "        \n",
    "    elif vardo =='TAUX': #correct for prescribed ocean... \n",
    "        plotter_obs = ERAi_weighted.sel(season=seas_do)\n",
    "        plotter_obs = plotter_obs.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "        \n",
    "        plotter_free = DS_free_weighted.sel(season=seas_do)\n",
    "        plotter_free = plotter_free.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "        \n",
    "        plotter_comp = DS_comp_weighted.sel(season=seas_do)\n",
    "        plotter_comp = plotter_comp.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "\n",
    "        #global\n",
    "        RMSE_dict_free[seas_do+'_global'].append(np.round(wgt_rmse(plotter_obs.sel(lat=slice(-87,87)),plotter_free.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "        RMSE_dict_comp[seas_do+'_global'].append(np.round(wgt_rmse(plotter_obs.sel(lat=slice(-87,87)),plotter_comp.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "\n",
    "        #extropics \n",
    "        plotter_free_extrop = plotter_free.where((lat>25)|(lat<-25),np.nan)\n",
    "        plotter_free_extrop = plotter_free_extrop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "        \n",
    "        plotter_comp_extrop = plotter_comp.where((lat>25)|(lat<-25),np.nan)\n",
    "        plotter_comp_extrop = plotter_comp_extrop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "\n",
    "        plotter_obs_extrop = plotter_obs.where((lat>25)|(lat<-25),np.nan)\n",
    "        plotter_obs_extrop = plotter_obs_extrop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "\n",
    "        RMSE_dict_free[seas_do+'_extrop'].append(np.round(wgt_rmse(plotter_obs_extrop.sel(lat=slice(-87,87)),plotter_free_extrop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "        RMSE_dict_comp[seas_do+'_extrop'].append(np.round(wgt_rmse(plotter_obs_extrop.sel(lat=slice(-87,87)),plotter_comp_extrop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "\n",
    "        #tropics \n",
    "        plotter_free_trop = plotter_free.where((lat<25)&(lat>-25),np.nan)\n",
    "        plotter_free_trop = plotter_free_trop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "\n",
    "        plotter_comp_trop = plotter_comp.where((lat<25)&(lat>-25),np.nan)\n",
    "        plotter_comp_trop = plotter_comp_trop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "        \n",
    "        plotter_obs_trop = plotter_obs.where((lat<25)&(lat>-25),np.nan)\n",
    "        plotter_obs_trop = plotter_obs_trop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "\n",
    "        RMSE_dict_free[seas_do+'_trop'].append(np.round(wgt_rmse(plotter_obs_trop.sel(lat=slice(-87,87)),plotter_free_trop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "        RMSE_dict_comp[seas_do+'_trop'].append(np.round(wgt_rmse(plotter_obs_trop.sel(lat=slice(-87,87)),plotter_comp_trop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "        \n",
    "    else:\n",
    "        plotter_obs = ERAi_weighted.sel(season=seas_do)\n",
    "        plotter_free = DS_free_weighted.sel(season=seas_do)\n",
    "        plotter_comp = DS_comp_weighted.sel(season=seas_do)\n",
    "\n",
    "        #global\n",
    "        RMSE_dict_free[seas_do+'_global'].append(np.round(wgt_rmse(plotter_obs.sel(lat=slice(-87,87)),plotter_free.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "        RMSE_dict_comp[seas_do+'_global'].append(np.round(wgt_rmse(plotter_obs.sel(lat=slice(-87,87)),plotter_comp.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "\n",
    "        #extropics \n",
    "        plotter_free_extrop = plotter_free.where((lat>25)|(lat<-25),np.nan)\n",
    "        plotter_comp_extrop = plotter_comp.where((lat>25)|(lat<-25),np.nan)\n",
    "        plotter_obs_extrop = plotter_obs.where((lat>25)|(lat<-25),np.nan)\n",
    "\n",
    "        RMSE_dict_free[seas_do+'_extrop'].append(np.round(wgt_rmse(plotter_obs_extrop.sel(lat=slice(-87,87)),plotter_free_extrop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "        RMSE_dict_comp[seas_do+'_extrop'].append(np.round(wgt_rmse(plotter_obs_extrop.sel(lat=slice(-87,87)),plotter_comp_extrop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "\n",
    "        #tropics \n",
    "        plotter_free_trop = plotter_free.where((lat<25)&(lat>-25),np.nan)\n",
    "        plotter_comp_trop = plotter_comp.where((lat<25)&(lat>-25),np.nan)\n",
    "        plotter_obs_trop = plotter_obs.where((lat<25)&(lat>-25),np.nan)\n",
    "\n",
    "        RMSE_dict_free[seas_do+'_trop'].append(np.round(wgt_rmse(plotter_obs_trop.sel(lat=slice(-87,87)),plotter_free_trop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "        RMSE_dict_comp[seas_do+'_trop'].append(np.round(wgt_rmse(plotter_obs_trop.sel(lat=slice(-87,87)),plotter_comp_trop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "    \n",
    "    if surf_var:\n",
    "        \n",
    "        if vardo==\"TREFHT\":\n",
    "            seas_do_lf = 'ANN'\n",
    "        else:\n",
    "            seas_do_lf = seas_do\n",
    "                \n",
    "        plotter_obs = ERAi_weighted.sel(season=seas_do)\n",
    "        plotter_free = DS_free_weighted.sel(season=seas_do)\n",
    "        plotter_comp = DS_comp_weighted.sel(season=seas_do)\n",
    "        \n",
    "        plotter_obs_ocean = plotter_obs.where(DS_LandFrac_season.sel(season=seas_do_lf).LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "        plotter_obs_land = plotter_obs.where(DS_LandFrac_season.sel(season=seas_do_lf).LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "        plotter_free_ocean = plotter_free.where(DS_LandFrac_season.sel(season=seas_do_lf).LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "        plotter_free_land = plotter_free.where(DS_LandFrac_season.sel(season=seas_do_lf).LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "        plotter_comp_ocean = plotter_comp.where(DS_LandFrac_season.sel(season=seas_do_lf).LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "        plotter_comp_land = plotter_comp.where(DS_LandFrac_season.sel(season=seas_do_lf).LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "\n",
    "        \n",
    "        #global\n",
    "        RMSE_dict_free[seas_do+'_land'].append(np.round(wgt_rmse(plotter_obs_land.sel(lat=slice(-87,87)),plotter_free_land.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "        RMSE_dict_comp[seas_do+'_land'].append(np.round(wgt_rmse(plotter_obs_land.sel(lat=slice(-87,87)),plotter_comp_land.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "        \n",
    "        #ocean\n",
    "        RMSE_dict_free[seas_do+'_ocean'].append(np.round(wgt_rmse(plotter_obs_ocean.sel(lat=slice(-87,87)),plotter_free_ocean.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "        RMSE_dict_comp[seas_do+'_ocean'].append(np.round(wgt_rmse(plotter_obs_ocean.sel(lat=slice(-87,87)),plotter_comp_ocean.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "                                                                \n",
    " \n",
    "    \n",
    "print('###################')\n",
    "print('...doing annual...')\n",
    "print('###################')\n",
    "\n",
    "#create annual: \n",
    "DS_free_annual=weighted_temporal_mean(DS_free_int.to_dataset(name=vardo),vardo)\n",
    "DS_comp_annual=weighted_temporal_mean(DS_comp_int.to_dataset(name=vardo),vardo)\n",
    "ERAi_annual=weighted_temporal_mean(ERAi.to_dataset(name=vardo),vardo)\n",
    "\n",
    "#set nan values\n",
    "DS_free_weighted = DS_free_weighted.where( DS_free_weighted != 0)\n",
    "DS_comp_weighted = DS_comp_weighted.where( DS_comp_weighted != 0)\n",
    "ERAi_weighted = ERAi_weighted.where( DS_comp_weighted != 0)\n",
    "\n",
    "lat = DS_free_int['lat']\n",
    "res_all = []\n",
    "all_inds = np.arange(0,29)\n",
    "\n",
    "for bs_ii in range(bs_nummy):\n",
    "    res = random.sample(list(all_inds),k=int(len(all_inds)*0.8))\n",
    "    if bs_ii % 20 ==0:\n",
    "        print(bs_ii)\n",
    "    DS_free_annual_temp = DS_free_annual.isel(time=res).mean('time')\n",
    "    DS_comp_annual_temp = DS_comp_annual.isel(time=res).mean('time')\n",
    "    ERAi_annual_temp = ERAi_annual.isel(time=res).mean('time')\n",
    "\n",
    "    #set nan values\n",
    "    \n",
    "    plotter_obs = ERAi_annual_temp\n",
    "    plotter_free = DS_free_annual_temp\n",
    "    plotter_comp = DS_comp_annual_temp\n",
    "    \n",
    "    if vardo == 'TREFHT':\n",
    "        #global\n",
    "        RMSE_dict_free['ANN_global'].append(np.round(wgt_rmse(plotter_obs.sel(lat=slice(-87,87)),plotter_free.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "        RMSE_dict_comp['ANN_global'].append(np.round(wgt_rmse(plotter_obs.sel(lat=slice(-87,87)),plotter_comp.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "\n",
    "        #extropics \n",
    "        plotter_free_extrop = plotter_free.where((lat>25)|(lat<-25),np.nan)\n",
    "        plotter_free_extrop = plotter_free_extrop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "\n",
    "        plotter_comp_extrop = plotter_comp.where((lat>25)|(lat<-25),np.nan)\n",
    "        plotter_comp_extrop = plotter_comp_extrop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "    \n",
    "        plotter_obs_extrop = plotter_obs.where((lat>25)|(lat<-25),np.nan)\n",
    "        plotter_obs_extrop = plotter_obs_extrop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "\n",
    "        RMSE_dict_free['ANN_extrop'].append(np.round(wgt_rmse(plotter_obs_extrop.sel(lat=slice(-87,87)),plotter_free_extrop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "        RMSE_dict_comp['ANN_extrop'].append(np.round(wgt_rmse(plotter_obs_extrop.sel(lat=slice(-87,87)),plotter_comp_extrop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "\n",
    "        #tropics \n",
    "        plotter_free_trop  = plotter_free.where((lat<25)&(lat>-25),np.nan)\n",
    "        plotter_free_trop = plotter_free_trop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "    \n",
    "        plotter_comp_trop = plotter_comp.where((lat<25)&(lat>-25),np.nan)\n",
    "        plotter_comp_trop = plotter_comp_trop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "    \n",
    "        plotter_obs_trop = plotter_obs.where((lat<25)&(lat>-25),np.nan)\n",
    "        plotter_obs_trop = plotter_obs_trop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "\n",
    "        RMSE_dict_free['ANN_trop'].append(np.round(wgt_rmse(plotter_obs_trop.sel(lat=slice(-87,87)),plotter_free_trop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "        RMSE_dict_comp['ANN_trop'].append(np.round(wgt_rmse(plotter_obs_trop.sel(lat=slice(-87,87)),plotter_comp_trop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "        \n",
    "    elif vardo == 'TAUX':\n",
    "        #global\n",
    "        RMSE_dict_free['ANN_global'].append(np.round(wgt_rmse(plotter_obs.sel(lat=slice(-87,87)),plotter_free.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "        RMSE_dict_comp['ANN_global'].append(np.round(wgt_rmse(plotter_obs.sel(lat=slice(-87,87)),plotter_comp.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "\n",
    "        #extropics \n",
    "        plotter_free_extrop = plotter_free.where((lat>25)|(lat<-25),np.nan)\n",
    "        plotter_free_extrop = plotter_free_extrop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "\n",
    "        plotter_comp_extrop = plotter_comp.where((lat>25)|(lat<-25),np.nan)\n",
    "        plotter_comp_extrop = plotter_comp_extrop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "    \n",
    "        plotter_obs_extrop = plotter_obs.where((lat>25)|(lat<-25),np.nan)\n",
    "        plotter_obs_extrop = plotter_obs_extrop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "\n",
    "        RMSE_dict_free['ANN_extrop'].append(np.round(wgt_rmse(plotter_obs_extrop.sel(lat=slice(-87,87)),plotter_free_extrop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "        RMSE_dict_comp['ANN_extrop'].append(np.round(wgt_rmse(plotter_obs_extrop.sel(lat=slice(-87,87)),plotter_comp_extrop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "\n",
    "        #tropics \n",
    "        plotter_free_trop  = plotter_free.where((lat<25)&(lat>-25),np.nan)\n",
    "        plotter_free_trop = plotter_free_trop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "    \n",
    "        plotter_comp_trop = plotter_comp.where((lat<25)&(lat>-25),np.nan)\n",
    "        plotter_comp_trop = plotter_comp_trop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "    \n",
    "        plotter_obs_trop = plotter_obs.where((lat<25)&(lat>-25),np.nan)\n",
    "        plotter_obs_trop = plotter_obs_trop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "\n",
    "        RMSE_dict_free['ANN_trop'].append(np.round(wgt_rmse(plotter_obs_trop.sel(lat=slice(-87,87)),plotter_free_trop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "        RMSE_dict_comp['ANN_trop'].append(np.round(wgt_rmse(plotter_obs_trop.sel(lat=slice(-87,87)),plotter_comp_trop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "        \n",
    "    else:\n",
    "        #global\n",
    "        RMSE_dict_free['ANN_global'].append(np.round(wgt_rmse(plotter_obs.sel(lat=slice(-87,87)),plotter_free.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "        RMSE_dict_comp['ANN_global'].append(np.round(wgt_rmse(plotter_obs.sel(lat=slice(-87,87)),plotter_comp.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "        \n",
    "        #extropics \n",
    "        plotter_free_extrop = plotter_free.where((lat>25)|(lat<-25),np.nan)\n",
    "        plotter_comp_extrop = plotter_comp.where((lat>25)|(lat<-25),np.nan)\n",
    "        plotter_obs_extrop = plotter_obs.where((lat>25)|(lat<-25),np.nan)\n",
    "    \n",
    "        RMSE_dict_free['ANN_extrop'].append(np.round(wgt_rmse(plotter_obs_extrop.sel(lat=slice(-87,87)),plotter_free_extrop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "        RMSE_dict_comp['ANN_extrop'].append(np.round(wgt_rmse(plotter_obs_extrop.sel(lat=slice(-87,87)),plotter_comp_extrop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "        \n",
    "        #tropics \n",
    "        plotter_free_trop = plotter_free.where((lat<25)&(lat>-25),np.nan)\n",
    "        plotter_comp_trop = plotter_comp.where((lat<25)&(lat>-25),np.nan)\n",
    "        plotter_obs_trop = plotter_obs.where((lat<25)&(lat>-25),np.nan)\n",
    "    \n",
    "        RMSE_dict_free['ANN_trop'].append(np.round(wgt_rmse(plotter_obs_trop.sel(lat=slice(-87,87)),plotter_free_trop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "        RMSE_dict_comp['ANN_trop'].append(np.round(wgt_rmse(plotter_obs_trop.sel(lat=slice(-87,87)),plotter_comp_trop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "    \n",
    "    if surf_var:\n",
    "        if vardo==\"TREFHT\":\n",
    "            seas_do_lf = 'ANN'\n",
    "        else:\n",
    "            seas_do_lf = seas_do\n",
    "                \n",
    "        plotter_obs = ERAi_annual_temp\n",
    "        plotter_free = DS_free_annual_temp\n",
    "        plotter_comp = DS_comp_annual_temp\n",
    "         \n",
    "        plotter_obs_ocean = plotter_obs.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "        plotter_obs_land = plotter_obs.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "        plotter_free_ocean = plotter_free.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "        plotter_free_land = plotter_free.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "        plotter_comp_ocean = plotter_comp.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "        plotter_comp_land = plotter_comp.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "        \n",
    "        #global\n",
    "        RMSE_dict_free['ANN_land'].append(np.round(wgt_rmse(plotter_obs_land.sel(lat=slice(-87,87)),plotter_free_land.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "        RMSE_dict_comp['ANN_land'].append(np.round(wgt_rmse(plotter_obs_land.sel(lat=slice(-87,87)),plotter_comp_land.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "        \n",
    "        #extropics\n",
    "        RMSE_dict_free['ANN_ocean'].append(np.round(wgt_rmse(plotter_obs_ocean.sel(lat=slice(-87,87)),plotter_free_ocean.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "        RMSE_dict_comp['ANN_ocean'].append(np.round(wgt_rmse(plotter_obs_ocean.sel(lat=slice(-87,87)),plotter_comp_ocean.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "        \n",
    "    \n",
    "DS_free_annual_temp = DS_free_annual.mean('time')\n",
    "DS_comp_annual_temp = DS_comp_annual.mean('time')\n",
    "ERAi_annual_temp = ERAi_annual.mean('time')\n",
    "\n",
    "plotter_obs = ERAi_annual_temp\n",
    "plotter_free = DS_free_annual_temp\n",
    "plotter_comp = DS_comp_annual_temp\n",
    "    \n",
    "    \n",
    "if vardo == 'TREFHT':\n",
    "    #global\n",
    "    RMSE_dict_free['ANN_global'].append(np.round(wgt_rmse(plotter_obs.sel(lat=slice(-87,87)),plotter_free.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "    RMSE_dict_comp['ANN_global'].append(np.round(wgt_rmse(plotter_obs.sel(lat=slice(-87,87)),plotter_comp.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "\n",
    "    #extropics \n",
    "    plotter_free_extrop = plotter_free.where((lat>25)|(lat<-25),np.nan)\n",
    "    plotter_free_extrop = plotter_free_extrop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "\n",
    "    plotter_comp_extrop = plotter_comp.where((lat>25)|(lat<-25),np.nan)\n",
    "    plotter_comp_extrop = plotter_comp_extrop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "    \n",
    "    plotter_obs_extrop = plotter_obs.where((lat>25)|(lat<-25),np.nan)\n",
    "    plotter_obs_extrop = plotter_obs_extrop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "\n",
    "    RMSE_dict_free['ANN_extrop'].append(np.round(wgt_rmse(plotter_obs_extrop.sel(lat=slice(-87,87)),plotter_free_extrop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "    RMSE_dict_comp['ANN_extrop'].append(np.round(wgt_rmse(plotter_obs_extrop.sel(lat=slice(-87,87)),plotter_comp_extrop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "\n",
    "    #tropics \n",
    "    plotter_free_trop  = plotter_free.where((lat<25)&(lat>-25),np.nan)\n",
    "    plotter_free_trop = plotter_free_trop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "    \n",
    "    plotter_comp_trop = plotter_comp.where((lat<25)&(lat>-25),np.nan)\n",
    "    plotter_comp_trop = plotter_comp_trop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "    \n",
    "    plotter_obs_trop = plotter_obs.where((lat<25)&(lat>-25),np.nan)\n",
    "    plotter_obs_trop = plotter_obs_trop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "\n",
    "    RMSE_dict_free['ANN_trop'].append(np.round(wgt_rmse(plotter_obs_trop.sel(lat=slice(-87,87)),plotter_free_trop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "    RMSE_dict_comp['ANN_trop'].append(np.round(wgt_rmse(plotter_obs_trop.sel(lat=slice(-87,87)),plotter_comp_trop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "\n",
    "elif vardo=='TAUX':\n",
    "    #global\n",
    "    RMSE_dict_free['ANN_global'].append(np.round(wgt_rmse(plotter_obs.sel(lat=slice(-87,87)),plotter_free.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "    RMSE_dict_comp['ANN_global'].append(np.round(wgt_rmse(plotter_obs.sel(lat=slice(-87,87)),plotter_comp.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "\n",
    "    #extropics \n",
    "    plotter_free_extrop = plotter_free.where((lat>25)|(lat<-25),np.nan)\n",
    "    plotter_free_extrop = plotter_free_extrop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "\n",
    "    plotter_comp_extrop = plotter_comp.where((lat>25)|(lat<-25),np.nan)\n",
    "    plotter_comp_extrop = plotter_comp_extrop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "    \n",
    "    plotter_obs_extrop = plotter_obs.where((lat>25)|(lat<-25),np.nan)\n",
    "    plotter_obs_extrop = plotter_obs_extrop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "\n",
    "    RMSE_dict_free['ANN_extrop'].append(np.round(wgt_rmse(plotter_obs_extrop.sel(lat=slice(-87,87)),plotter_free_extrop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "    RMSE_dict_comp['ANN_extrop'].append(np.round(wgt_rmse(plotter_obs_extrop.sel(lat=slice(-87,87)),plotter_comp_extrop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "\n",
    "    #tropics \n",
    "    plotter_free_trop  = plotter_free.where((lat<25)&(lat>-25),np.nan)\n",
    "    plotter_free_trop = plotter_free_trop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "    \n",
    "    plotter_comp_trop = plotter_comp.where((lat<25)&(lat>-25),np.nan)\n",
    "    plotter_comp_trop = plotter_comp_trop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "    \n",
    "    plotter_obs_trop = plotter_obs.where((lat<25)&(lat>-25),np.nan)\n",
    "    plotter_obs_trop = plotter_obs_trop.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "\n",
    "    RMSE_dict_free['ANN_trop'].append(np.round(wgt_rmse(plotter_obs_trop.sel(lat=slice(-87,87)),plotter_free_trop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "    RMSE_dict_comp['ANN_trop'].append(np.round(wgt_rmse(plotter_obs_trop.sel(lat=slice(-87,87)),plotter_comp_trop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "else: \n",
    "    #global\n",
    "    RMSE_dict_free['ANN_global'].append(np.round(wgt_rmse(plotter_obs.sel(lat=slice(-87,87)),plotter_free.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "    RMSE_dict_comp['ANN_global'].append(np.round(wgt_rmse(plotter_obs.sel(lat=slice(-87,87)),plotter_comp.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "\n",
    "    #extropics \n",
    "    plotter_free_extrop = plotter_free.where((lat>25)|(lat<-25),np.nan)\n",
    "    plotter_comp_extrop = plotter_comp.where((lat>25)|(lat<-25),np.nan)\n",
    "    plotter_obs_extrop = plotter_obs.where((lat>25)|(lat<-25),np.nan)\n",
    "\n",
    "    RMSE_dict_free['ANN_extrop'].append(np.round(wgt_rmse(plotter_obs_extrop.sel(lat=slice(-87,87)),plotter_free_extrop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "    RMSE_dict_comp['ANN_extrop'].append(np.round(wgt_rmse(plotter_obs_extrop.sel(lat=slice(-87,87)),plotter_comp_extrop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "\n",
    "    #tropics \n",
    "    plotter_free_trop = plotter_free.where((lat<25)&(lat>-25),np.nan)\n",
    "    plotter_comp_trop = plotter_comp.where((lat<25)&(lat>-25),np.nan)\n",
    "    plotter_obs_trop = plotter_obs.where((lat<25)&(lat>-25),np.nan)\n",
    "\n",
    "    RMSE_dict_free['ANN_trop'].append(np.round(wgt_rmse(plotter_obs_trop.sel(lat=slice(-87,87)),plotter_free_trop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "    RMSE_dict_comp['ANN_trop'].append(np.round(wgt_rmse(plotter_obs_trop.sel(lat=slice(-87,87)),plotter_comp_trop.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "\n",
    "\n",
    "if surf_var:\n",
    "    plotter_obs = ERAi_annual_temp\n",
    "    plotter_free = DS_free_annual_temp\n",
    "    plotter_comp = DS_comp_annual_temp\n",
    "    \n",
    "    plotter_obs_ocean = plotter_obs.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "    plotter_obs_land = plotter_obs.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "    plotter_free_ocean = plotter_free.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "    plotter_free_land = plotter_free.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "    plotter_comp_ocean = plotter_comp.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC<=LF_scale,np.nan).squeeze()\n",
    "    plotter_comp_land = plotter_comp.where(DS_LandFrac_season.sel(season='ANN').LANDFRAC>=LF_scale,np.nan).squeeze()\n",
    "        \n",
    "        \n",
    "    #land\n",
    "    RMSE_dict_free['ANN_land'].append(np.round(wgt_rmse(plotter_obs_land.sel(lat=slice(-87,87)),plotter_free_land.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "    RMSE_dict_comp['ANN_land'].append(np.round(wgt_rmse(plotter_obs_land.sel(lat=slice(-87,87)),plotter_comp_land.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "        \n",
    "    #ocean\n",
    "    RMSE_dict_free['ANN_ocean'].append(np.round(wgt_rmse(plotter_obs_ocean.sel(lat=slice(-87,87)),plotter_free_ocean.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "    RMSE_dict_comp['ANN_ocean'].append(np.round(wgt_rmse(plotter_obs_ocean.sel(lat=slice(-87,87)),plotter_comp_ocean.sel(lat=slice(-87,87)),weights_cos.sel(lat=slice(-87,87))),3))\n",
    "        \n",
    "print('...done bootstrapping...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6c937e2-2f55-4db2-abf4-6edcb0285ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir_text = '/glade/u/home/wchapman/ADF/RMSE_text/'\n",
    "outfil = outdir_text + vardo+'_'+str(levdo)+'mb_obsvar_'+vardo_era+'_'+freemod+'.txt'\n",
    "\n",
    "if os.path.exists(outfil):\n",
    "    os.remove(outfil)\n",
    "\n",
    "with open(outfil, 'a') as the_file:\n",
    "    the_file.write('model name: '+ freemod +'\\n')\n",
    "    \n",
    "    for keekee in RMSE_dict_free.keys():\n",
    "        if len(np.array(RMSE_dict_free[keekee])) > 0:\n",
    "            the_file.write('################################### \\n')\n",
    "            \n",
    "            the_file.write(keekee + ' mean:               '+ str(np.array(RMSE_dict_free[keekee])[-1]) +'\\n')\n",
    "            the_file.write(keekee + ' 5th percentile:     '+ str(np.percentile(np.array(RMSE_dict_free[keekee]),5))+'\\n')\n",
    "            the_file.write(keekee + ' 95th percentile:    '+ str(np.percentile(np.array(RMSE_dict_free[keekee]),95))+'\\n')\n",
    "            \n",
    "            the_file.write('################################### \\n')\n",
    "            \n",
    "            \n",
    "outdir_text = '/glade/u/home/wchapman/ADF/RMSE_text/'\n",
    "outfil = outdir_text + vardo+'_'+str(levdo)+'mb_obsvar_'+vardo_era+'_'+compare_model+'.txt'\n",
    "\n",
    "if os.path.exists(outfil):\n",
    "    os.remove(outfil)\n",
    "\n",
    "with open(outfil, 'a') as the_file:\n",
    "    the_file.write('model name: '+ compare_model +'\\n')\n",
    "    \n",
    "    for keekee in RMSE_dict_comp.keys():\n",
    "        if len(np.array(RMSE_dict_comp[keekee])) > 0:\n",
    "            the_file.write('################################### \\n')\n",
    "            perc_improve = (np.array(RMSE_dict_free[keekee])[-1] - np.array(RMSE_dict_comp[keekee])[-1])/np.array(RMSE_dict_free[keekee])[-1]\n",
    "            perc_improve = np.round(perc_improve,4)\n",
    "            the_file.write(keekee + ' mean:               '+ str(np.array(RMSE_dict_comp[keekee])[-1]) +'\\n')\n",
    "            the_file.write(keekee + ' perc improved:      '+ str(perc_improve*100) +' %\\n')\n",
    "            the_file.write(keekee + ' 5th percentile:     '+ str(np.percentile(np.array(RMSE_dict_comp[keekee]),5))+'\\n')\n",
    "            the_file.write(keekee + ' 95th percentile:    '+ str(np.percentile(np.array(RMSE_dict_comp[keekee]),95))+'\\n')\n",
    "            the_file.write('################################### \\n')\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f39cdf-d524-4d88-95b2-296ab353bf5e",
   "metadata": {},
   "source": [
    "## Do Excell Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd11edaa-df91-4c39-9744-a38f2106209a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xlsxwriter in /glade/u/home/wchapman/.local/lib/python3.9/site-packages (3.0.8)\n",
      "/glade/u/home/wchapman/ADF/RMSE_text/VpQp_850mb_obsvar_VpQp_f.e21.DAcompset.f09_d025_Seasonal_stochai_UV_00_1982.xlsx\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "!pip install xlsxwriter\n",
    "import xlsxwriter\n",
    "Seas_All = ['DJF','MAM','JJA','SON','ANN']\n",
    "stind = [1,12,23,34,45]\n",
    "\n",
    "outdir_text = '/glade/u/home/wchapman/ADF/RMSE_text/'\n",
    "outfil = outdir_text + vardo+'_'+str(levdo)+'mb_obsvar_'+vardo_era+'_'+compare_model+'.xlsx'\n",
    "if os.path.exists(outfil):\n",
    "    os.remove(outfil)\n",
    "    \n",
    "workbook = xlsxwriter.Workbook(outfil)\n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "\n",
    "for br,seas in enumerate(Seas_All):\n",
    "    ii = stind[br]\n",
    "    # Create an new Excel file and add a worksheet.\n",
    "\n",
    "    # Increase the cell size of the merged cells to highlight the formatting.\n",
    "    # worksheet.set_column('B:D', 12)\n",
    "    worksheet.set_column('A:E', 12)\n",
    "    worksheet.set_row(3, 30)\n",
    "    worksheet.set_row(6, 30)\n",
    "    worksheet.set_row(7, 30)\n",
    "\n",
    "    # Create a format to use in the merged range.\n",
    "    merge_format = workbook.add_format({\n",
    "        'bold': 1,\n",
    "        'border': 1,\n",
    "        'align': 'center',\n",
    "        'valign': 'vcenter',\n",
    "        'fg_color': 'gray',\n",
    "        'font_color':'white'})\n",
    "\n",
    "    merge_format1 = workbook.add_format({\n",
    "        'bold': 1,\n",
    "        'border': 2,\n",
    "        'align': 'center',\n",
    "        'valign': 'vcenter',\n",
    "        'fg_color': 'gray',\n",
    "        'font_color':'white'})\n",
    "\n",
    "    merge_format2 = workbook.add_format({\n",
    "        'border': 2,\n",
    "        'align': 'center',\n",
    "        'valign': 'vcenter'})\n",
    "\n",
    "    num_format = workbook.add_format({\n",
    "        'border': 2,\n",
    "        'align': 'center',\n",
    "        'valign': 'vcenter'})\n",
    "\n",
    "    head_format = workbook.add_format({\n",
    "        'border': 2,\n",
    "        'align': 'center',\n",
    "        'valign': 'vcenter',\n",
    "        'fg_color': 'gray',\n",
    "        'font_color':'white'})\n",
    "\n",
    "    # Merge 3 cells.\n",
    "    worksheet.merge_range('A'+str(ii+2)+':A'+str(ii+11), seas, merge_format)\n",
    "    # Merge 3 cells over two rows.\n",
    "    worksheet.merge_range('C'+str(ii+1)+':E'+str(ii+1), vardo, merge_format1)\n",
    "    # Merge 3 cells over two rows.\n",
    "    bigtime=['B','C','D']\n",
    "    dd =0 \n",
    "    Varputy= ['Land','Ocean','Tropics','Extra Tropics', 'Global']\n",
    "    Varputy_keys = ['_land','_ocean','_trop','_extrop','_global']\n",
    "    for ee,dodo in enumerate(bigtime):\n",
    "\n",
    "        if ee==0:\n",
    "            Varput = Varputy\n",
    "        elif ee==1:\n",
    "            Varput = []\n",
    "            for metric_ in Varputy_keys:\n",
    "\n",
    "                if len(RMSE_dict_free[seas+metric_])==0:\n",
    "                    Varput.append('---')\n",
    "                else:\n",
    "                    perimp = (np.array(RMSE_dict_free[seas+metric_])[-1] - np.array(RMSE_dict_comp[seas+metric_])[-1])/np.array(RMSE_dict_free[seas+metric_])[-1]   \n",
    "                    perimp = perimp *100\n",
    "                    perimp = np.round(perimp,2)\n",
    "                    Varput.append(str(perimp)+'%')\n",
    "\n",
    "\n",
    "        elif ee==2:\n",
    "            Varput = []\n",
    "            for metric_ in Varputy_keys:\n",
    "\n",
    "                if len(RMSE_dict_free[seas+metric_])==0:\n",
    "                    Varput.append('---')\n",
    "                else:\n",
    "                    Varput.append(str(np.round(np.array(RMSE_dict_comp[seas+metric_])[-1],4)))\n",
    "                    \n",
    "        worksheet.merge_range(dodo+str(ii+dd+2)+':'+dodo+str(ii+dd+3), Varput[0], merge_format2)\n",
    "        worksheet.merge_range(dodo+str(ii+dd+4)+':'+dodo+str(ii+dd+5), Varput[1], merge_format2)\n",
    "        worksheet.merge_range(dodo+str(ii+dd+6)+':'+dodo+str(ii+dd+7), Varput[2], merge_format2)\n",
    "        worksheet.merge_range(dodo+str(ii+dd+8)+':'+dodo+str(ii+dd+9), Varput[3], merge_format2)\n",
    "        worksheet.merge_range(dodo+str(ii+dd+10)+':'+dodo+str(ii+dd+11), Varput[4], merge_format2)\n",
    "\n",
    "    if len(RMSE_dict_comp[seas+'_land'])==0:\n",
    "        worksheet.write('E'+str(ii+2),'--',num_format)\n",
    "        worksheet.write('E'+str(ii+3),'--',num_format)\n",
    "    else:\n",
    "        worksheet.write('E'+str(ii+2),str(np.percentile(np.array(RMSE_dict_comp[seas+'_land']),5)),num_format)\n",
    "        worksheet.write('E'+str(ii+3),str(np.percentile(np.array(RMSE_dict_comp[seas+'_land']),95)),num_format)\n",
    "    if len(RMSE_dict_comp[seas+'_ocean'])==0:\n",
    "        worksheet.write('E'+str(ii+4),'--',num_format)\n",
    "        worksheet.write('E'+str(ii+5),'--',num_format)\n",
    "    else:\n",
    "        worksheet.write('E'+str(ii+4),str(np.percentile(np.array(RMSE_dict_comp[seas+'_ocean']),5)),num_format)\n",
    "        worksheet.write('E'+str(ii+5),str(np.percentile(np.array(RMSE_dict_comp[seas+'_ocean']),95)),num_format)\n",
    "\n",
    "    if len(RMSE_dict_comp[seas+'_trop'])==0:\n",
    "        worksheet.write('E'+str(ii+6),'--',num_format)\n",
    "        worksheet.write('E'+str(ii+7),'--',num_format)\n",
    "    else:\n",
    "        worksheet.write('E'+str(ii+6),str(np.percentile(np.array(RMSE_dict_comp[seas+'_trop']),5)),num_format)\n",
    "        worksheet.write('E'+str(ii+7),str(np.percentile(np.array(RMSE_dict_comp[seas+'_trop']),95)),num_format)\n",
    "\n",
    "    if len(RMSE_dict_comp[seas+'_extrop'])==0:\n",
    "        worksheet.write('E'+str(ii+8),'--',num_format)\n",
    "        worksheet.write('E'+str(ii+9),'--',num_format)\n",
    "    else:\n",
    "        worksheet.write('E'+str(ii+8),str(np.percentile(np.array(RMSE_dict_comp[seas+'_extrop']),5)),num_format)\n",
    "        worksheet.write('E'+str(ii+9),str(np.percentile(np.array(RMSE_dict_comp[seas+'_extrop']),95)),num_format)\n",
    "\n",
    "    if len(RMSE_dict_comp[seas+'_global'])==0:\n",
    "        worksheet.write('E'+str(ii+10),'--',num_format)\n",
    "        worksheet.write('E'+str(ii+11),'--',num_format)\n",
    "    else:\n",
    "        worksheet.write('E'+str(ii+10),str(np.percentile(np.array(RMSE_dict_comp[seas+'_global']),5)),num_format)\n",
    "        worksheet.write('E'+str(ii+11),str(np.percentile(np.array(RMSE_dict_comp[seas+'_global']),95)),num_format)\n",
    "\n",
    "    worksheet.write('A'+str(ii+1),' ',head_format)\n",
    "    worksheet.write('B'+str(ii+1),' ',head_format)\n",
    "workbook.close()\n",
    "print(outfil)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77a8ccf-6222-4a0e-ae9f-53cafa64c65c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2e73fb-7ff2-40e4-8743-5ec8aa116048",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL 2023a",
   "language": "python",
   "name": "npl-2023a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
